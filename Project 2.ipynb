{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24a85959-71c6-41bd-8d92-b9407839597f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"\n",
       "    display: flex; \n",
       "    align-items: center; \n",
       "    justify-content: space-between; \n",
       "    background-color: #f9f9f9; \n",
       "    padding: 20px; \n",
       "    border-radius: 10px; \n",
       "    border: 1px solid #ddd; \n",
       "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
       "\">\n",
       "    <div style=\"flex: 3; font-family: Arial, sans-serif;\">\n",
       "        <h2 style=\"margin: 0; color: #333;\">Indus Valley Civilization Script Clustering Project</h2>\n",
       "        <p style=\"font-size: 16px; color: #555; line-height: 1.6;\">\n",
       "            Welcome to this notebook! This project delves into clustering the ancient Indus Valley script images \n",
       "            using advanced deep learning techniques for feature extraction and K-means clustering. By leveraging \n",
       "            state-of-the-art methods, we aim to uncover hidden patterns in this historically rich dataset.\n",
       "        </p>\n",
       "        <p style=\"font-size: 14px; color: #777; margin-top: 10px;\">\n",
       "            <strong>Author:</strong> Shubham Bhilare<br>\n",
       "            _Exploring the intersection of AI, history, and data science._\n",
       "        </p>\n",
       "        <p style=\"font-size: 14px; color: #999; font-style: italic;\">\n",
       "            “Bringing ancient history to life with the power of modern AI.”\n",
       "        </p>\n",
       "    </div>\n",
       "    <div style=\"flex: 1; text-align: right;\">\n",
       "        <img src=\"1.png\" alt=\"Author Image\" style=\"\n",
       "            max-width: 120px; \n",
       "            border-radius: 50%; \n",
       "            border: 2px solid #ddd; \n",
       "            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1); \n",
       "        \"/>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98316d86-7764-47c9-893c-2e4965cfe114",
   "metadata": {},
   "source": [
    "# 1. Data Augmentation for generating images for train:test (80:20 ratio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b59e4a-c096-4566-a9c0-3766b94199fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "# base directory to extract images\n",
    "base_dir = \"data_set\"\n",
    "\n",
    "# augmented images directory\n",
    "aug_dir1 = \"augmented_set1\"\n",
    "os.makedirs(aug_dir1, exist_ok=True)\n",
    "aug_dir2 = \"augmented_set2\"\n",
    "os.makedirs(aug_dir2, exist_ok=True)\n",
    "\n",
    "# train and test directories\n",
    "train_dir = os.path.join(aug_dir1, \"train_set\")\n",
    "test_dir = os.path.join(aug_dir2, \"test_set\")\n",
    "\n",
    "# Create directories if not present\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    " # Data augmentation\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Generate augmented images\n",
    "def generate_augmented_images(base_dir, augmented_dir, batch_size=1, num_augmented_images=50):\n",
    "    os.makedirs(augmented_dir, exist_ok=True)\n",
    "\n",
    "    # Get the list of images in the base directory\n",
    "    images = os.listdir(base_dir)\n",
    "\n",
    "    for img_name in images:\n",
    "        img_path = os.path.join(base_dir, img_name)\n",
    "        img = load_img(img_path)  # Load the image\n",
    "        x = img_to_array(img)  # Convert the image to numpy array\n",
    "        x = np.expand_dims(x, axis=0)  # Add batch dimension\n",
    "\n",
    "        # Create augmented images for this one image\n",
    "        i = 0\n",
    "        for batch in data_gen.flow(x, batch_size=batch_size, save_to_dir=augmented_dir, save_prefix=img_name, save_format='jpeg'):\n",
    "            i += 1\n",
    "            if i >= num_augmented_images:\n",
    "                break\n",
    "\n",
    "# for training\n",
    "generate_augmented_images(base_dir, train_dir)\n",
    "# for testing\n",
    "generate_augmented_images(base_dir, test_dir,num_augmented_images=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48e98f1-6098-44ca-a17d-b0060284fe50",
   "metadata": {},
   "source": [
    "# 2. Using VGG16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5926d31-237c-489f-8013-da82d7453895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Increase recurssion limit (temporary solution)\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "# Load the VGG16 model pre-trained on ImageNet\n",
    "base_model = VGG16(weights='imagenet', include_top=False,\n",
    "                 input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a new model and add the base model and new layers\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Load and preprocess the dataset for training\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'augmented_set1',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb',\n",
    ")\n",
    "\n",
    "# Load and preprocess the dataset for validating\n",
    "validate_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validate_generator = validate_datagen.flow_from_directory(\n",
    "    'validation_set',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb',\n",
    ")\n",
    "\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "# Train the model\n",
    "history = model.fit(train_generator, epochs=10, callbacks=[early_stopping], validation_data=validate_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef75e739-cb5c-4c2f-9019-23652fabb083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4e428a-de7e-4f1f-9d31-0ff2aa0bd1d9",
   "metadata": {},
   "source": [
    "# 3. Fine-tunning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bbe2f9-ec57-4fc8-8bfd-b97032a6bc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "# Gradually unfreeze layers\n",
    "for layer in model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "\n",
    "# Compile model again with lower learning rate for fine-tunning\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "# Load and preprocess the dataset for training\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'augmented_set2', # as my machine is not compatible to huge data we will use small Dummy_train set\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb',\n",
    ")\n",
    "\n",
    "# Load and preprocess the dataset for training\n",
    "validate_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validate_generator = validate_datagen.flow_from_directory(\n",
    "    'validation_set',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb',\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "# Train the model\n",
    "history = model.fit(train_generator, epochs=10, callbacks=[early_stopping], validation_data=validate_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2744c22e-830e-4a14-b49e-e36ecdf11942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8029f294-1315-40ff-b0a0-1397f6675904",
   "metadata": {},
   "source": [
    "# 4. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8160bb-e818-4555-a7d4-826f046d9280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset for training\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'augmented_set2',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb',\n",
    ")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Get features from the model\n",
    "features = model.predict(test_generator)\n",
    "\n",
    "# Flatten the features (e.g., for a convolutional layer)\n",
    "flattened_features = features.reshape(features.shape[0], -1)  # (num_images, feature_vector_size)\n",
    "\n",
    "print(\"Feature shape:\", flattened_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9893bc-a6e9-491f-953d-1b91860604c4",
   "metadata": {},
   "source": [
    "# 5. Using K-means clustering for clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1409cb59-78ea-4e67-888b-b011d7e4a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Define the number of clusters\n",
    "num_clusters = 21  # Adjust based on your dataset and task\n",
    "\n",
    "# Train k-means on the feature vectors\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(flattened_features)\n",
    "\n",
    "# Get the cluster labels for each image\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "print(\"Cluster labels:\", cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fac845c2-217d-4b9c-a436-84518d2bfe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with filenames and cluster labels\n",
    "filenames = test_generator.filenames  # List of image file paths\n",
    "results_df = pd.DataFrame({'Filename': filenames, 'Cluster': cluster_labels})\n",
    "\n",
    "# Save to a CSV file\n",
    "results_df.to_csv('clustering_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1430cd-d6ae-46f5-9797-871e39444c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Check feature dimensions\n",
    "print(\"Feature shape:\", flattened_features.shape)  # (n_samples, n_features)\n",
    "\n",
    "# Adjust n_components based on dataset size\n",
    "num_samples, num_features = flattened_features.shape\n",
    "n_components = min(2, num_samples, num_features)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=n_components)\n",
    "reduced_features = pca.fit_transform(flattened_features)\n",
    "\n",
    "print(\"Reduced features shape:\", reduced_features.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
